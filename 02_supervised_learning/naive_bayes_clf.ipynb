{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "import mglearn\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Classifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tend to be even faster in training in comparison to linear models, but often provide generalization performance that is slightly worse than that of linear classifiers like LogisticRegression and LinearSVC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learns each feature individualls and collect simple per-class statistics from each feature.\n",
    "Three kinds of naive Bayes classifiers implemented in scikit-learn:\n",
    "- GaussianNB\n",
    "- BernoulliNB\n",
    "- MultinomialNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gaussian applies to any continuous data, while BernoulliNB assumes binary data, and Multinomial assumes count data (that is, that each feature represents an integer count of something.)\n",
    "BernoulliNB, and MultinomialNB are mostly used in text data classification.BernoulliNB classifier counts how often every feature of each class is not zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [0 1 0 1] [ True False  True False] [[0 1 0 1]\n",
      " [0 0 0 1]]\n",
      "1 [0 1 0 1] [False  True False  True] [[1 0 1 1]\n",
      " [1 0 1 0]]\n",
      "Feature counts:\n",
      "{0: array([0, 1, 0, 2]), 1: array([2, 0, 2, 1])}\n"
     ]
    }
   ],
   "source": [
    "X = np.array([[0,1,0,1],\n",
    "             [1,0,1,1],\n",
    "             [0,0,0,1],\n",
    "             [1,0,1,0]])\n",
    "y = np.array([0,1,0,1])\n",
    "\n",
    "counts = {}\n",
    "for label in np.unique(y):\n",
    "    # iterate over each class\n",
    "    # count (sum) entries of 1 per feature\n",
    "    counts[label] = X[y == label].sum(axis=0)\n",
    "    print(label, y, y==label, X[y==label])\n",
    "print(\"Feature counts:\\n{}\".format(counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MultinomialNB and BernoulliNB make a prediction by comparing a data point to the statistics (average value of each feature for each class and the standard deviation when using GaussianNB) and the best matching class is predicted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## strengths, weaknesses, and parameters\n",
    "- BernoulliNB, GaussianNB, and MultinomialNB all have a single parameter, *alpha*, which controls model complexity. Adding *alpha* many virtual data points that have positive values for all the features. \"Smoothing\" the statistics. The more smoothing the less complex the model. Tuning the model usuallly improves accuracy, but the algorithm's performance is relatively robust and is not critical for a good performance.\n",
    "- GaussianNB is mostly used on very high-dimensional data, while the other two are used for sparse count data. MultinomialNB ususally performs better than BinaryNB, particularly on datasets with a relatively large number of nonzero features (i.e. large documents).\n",
    "- Fast to train and predict\n",
    "- training procedure is easy to understand\n",
    "- work well with high-dimensional sparse data\n",
    "- relatively robust to the parameters\n",
    "- great baseline models\n",
    "- used when even training a linear model might take too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
